# 세션 요약 - 2025년 2월 9일 (최종 업데이트: 2026년 2월 19일)

## 완료된 작업

### 1. AWS 인프라 배포
- 모든 CDK 스택 배포 완료 (Secrets, Network, Storage, Auth, Compute, API, Web)
- Docker 이미지 빌드 및 ECR 푸시 완료
- API Endpoints:
  - HTTP API: https://7gjo0uypi5.execute-api.ap-northeast-2.amazonaws.com
  - WebSocket API: wss://jn8dnp7is3.execute-api.ap-northeast-2.amazonaws.com/prod

### 2. Web UI Runtime Config 구현
- 문제: 빌드타임 환경변수(VITE_*)로는 CloudFormation Output 값을 주입할 수 없음
- 해결: 런타임 config.json 방식으로 변경
  - WebStack이 CloudFormation Output에서 config.json 자동 생성 및 S3 배포
  - Web App이 시작 시 config.json 로드하여 Cognito 설정 적용
- 수정 파일: `packages/cdk/lib/stacks/web-stack.ts`, `packages/web/src/config.ts`, `packages/web/src/main.tsx`, `packages/web/src/services/auth.ts`, `packages/web/src/components/Chat/ChatContainer.tsx`

### 3. Cognito 사용자 생성 및 로그인
- UserPoolId: ap-northeast-2_lpJNz3cLy
- ClientId: 4f6ucnfrf433v672kql4q3oudv
- Web UI 로그인 성공

### 4. OpenClaw Config 형식 수정 및 OpenRouter 연동 성공 ✅
**초기 문제:**
- Anthropic API: 크레딧 부족
- OpenAI API: quota 초과

**해결 과정:**
1. OpenRouter 무료 모델 테스트 (`arcee-ai/trinity-large-preview:free`)
2. OpenClaw Config 형식 학습 및 시행착오
   - 공식 문서: https://docs.openclaw.ai/concepts/model-providers
   - 사용자 제공 lmstudio 예시 참고
   - `gateway.mode: "local"` 필수
   - Config 형식: `agents.defaults` (복수) + `models.providers.<provider>.baseUrl` 필수

3. Config 형식 시행착오
   - 처음: 단순 `llm` 형식 → Gateway가 Anthropic으로 덮어씀
   - 다음: `models` + `agents.default` (단수) → 실패
   - 최종: `agents.defaults` (복수) + `models.providers` → **성공!**

**최종 성공 Config (OpenRouter):**
```json
{
  "gateway": {"port": 18789, "mode": "local"},
  "agents": {
    "defaults": {
      "model": {"primary": "openrouter/arcee-ai/trinity-large-preview:free"},
      "models": {
        "openrouter/arcee-ai/trinity-large-preview:free": {"alias": "Trinity Large Preview Free"}
      }
    }
  },
  "models": {
    "providers": {
      "openrouter": {
        "baseUrl": "https://openrouter.ai/api/v1",
        "apiKey": "OPENROUTER_API_KEY",
        "api": "openai-completions",
        "models": [
          {
            "id": "arcee-ai/trinity-large-preview:free",
            "name": "Trinity Large Preview Free",
            "reasoning": false,
            "input": ["text"],
            "cost": {"input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0},
            "contextWindow": 32000,
            "maxTokens": 4096
          }
        ]
      }
    }
  }
}
```

**배포 및 테스트:**
- DEPLOYMENT_VERSION: 2026.02.09.7
- ComputeStack 및 ApiStack 재배포 완료
- TaskState 리셋 완료
- **Web UI 테스트 성공**: 메시지 전송 및 응답 수신 확인 ✅
- 로그 확인: `agent model: openrouter/arcee-ai/trinity-large-preview:free`

**중요 발견:**
- `agents.defaults` (복수) 사용 필수
- `model.primary` 형식으로 모델 지정
- `models.providers.<provider>` 구조에 `baseUrl`, `apiKey`, `api` 필드 필요
- 각 model에 `reasoning`, `input`, `cost`, `contextWindow`, `maxTokens` 필드 포함
- OpenClaw Gateway가 config를 자동으로 덮어쓰지만, 올바른 형식이면 의도한 모델 사용

**현재 API 키 상태:**
- Anthropic API: 사용 불가 (크레딧 부족)
- OpenAI API: 사용 불가 (quota 초과)
- OpenRouter API: **작동 중** ✅ (`arcee-ai/trinity-large-preview:free`)
- Google Gemini API: **작동 중** ✅ (`gemini-3-flash-preview`, Primary 모델)

### 5. Telegram Webhook 설정 완료 ✅
- SSM Parameter에 `TELEGRAM_BOT_TOKEN` 추가 완료
- `make telegram-webhook` 실행으로 webhook 등록 성공
- Webhook URL: `https://7gjo0uypi5.execute-api.ap-northeast-2.amazonaws.com/telegram`
- Webhook 상태 확인: pending_update_count: 0 (정상)
- Bot: @geoseong_bot

### 6. 중요 발견 사항

**OpenClaw Gateway 동작:**
- Config 파일을 자동으로 덮어씀 (`Config overwrite` 로그)
- `gateway.mode: "local"` 필수
- Google provider는 직접 설정 가능 (OpenRouter 통하지 않음)
- Fallback 체인 지원: primary → fallbacks 순서대로 시도

**TaskState 관리 문제:**
- 컨테이너 실패 시 DynamoDB TaskState가 "Starting" 상태로 남음
- 새 컨테이너 시작 전 수동으로 TaskState 삭제 필요
- 명령어:
```bash
aws dynamodb delete-item \
  --table-name serverless-openclaw-TaskState \
  --key '{"PK":{"S":"USER#<user-id>"}}' \
  --region ap-northeast-2
```

**Lambda 환경변수 업데이트:**
- ComputeStack 배포 후 ApiStack도 배포해야 Lambda가 새 TaskDefinition 사용
- `DEPLOYMENT_VERSION` 증가시켜 Lambda 강제 업데이트

### 7. Google Gemini 모델 추가 완료 ✅
**최종 상태:**
- SSM Parameter에 `GEMINI_API_KEY` 추가 완료
- ComputeStack에 환경변수 설정 완료
- `packages/container/openclaw.json`에 Gemini를 primary 모델로 설정
- DEPLOYMENT_VERSION: 2026.02.09.9
- TaskDefinition: revision 10
- **Telegram 테스트 성공**: 응답 수신 확인 ✅
- **로그 확인**: `agent model: google/gemini-3-flash-preview` ✅

**중요 발견:**
- OpenClaw가 Google provider를 Built-in으로 지원
- 환경변수 `GEMINI_API_KEY`만 설정하면 자동으로 사용 가능
- Config에 `models.providers.google` 설정 불필요
- `agents.defaults.model.primary: "google/gemini-3-flash-preview"` 형식으로 지정

**모델 버전:**
- `gemini-1.5-flash`: 404 에러 (NOT_FOUND) ❌
- `gemini-3-flash-preview`: 작동 확인 ✅

**최종 Config:**
```json
{
  "gateway": {"port": 18789, "mode": "local"},
  "agents": {
    "defaults": {
      "model": {"primary": "google/gemini-3-flash-preview"},
      "models": {
        "google/gemini-3-flash-preview": {"alias": "Gemini 3 Flash Preview"},
        "openrouter/arcee-ai/trinity-large-preview:free": {"alias": "Trinity Large Preview Free"}
      }
    }
  }
}
```

## 다음 작업

### 1. 한글 입력 중복 문제 해결
- **문제**: "이름이 뭐야" 입력 시 ["이름이 뭐야", "야"] 2번 전송
- **원인**: IME (Input Method Editor) compositionend 이벤트 처리 누락

### 2. 한글 입력 중복 문제 해결
- **문제**: "이름이 뭐야" 입력 시 ["이름이 뭐야", "야"] 2번 전송
- **원인**: IME (Input Method Editor) compositionend 이벤트 처리 누락
- **해결 방법**: `packages/web/src/components/Chat/ChatContainer.tsx`에서 한글 입력 이벤트 처리 로직 수정

### 3. Ollama 관련 코드 정리
Ollama는 GPU 인스턴스가 필요하므로 현재 아키텍처(Fargate)에서 사용 불가. 관련 코드 및 설정 제거:

**제거할 항목:**
- SSM Parameters:
  - `/serverless-openclaw/OLLAMA_API_KEY` (존재한다면)
  - `/serverless-openclaw/OLLAMA_BASE_URL` (존재한다면)
- `packages/cdk/lib/stacks/ssm-params.ts`: Ollama 관련 파라미터 정의
- `packages/cdk/lib/stacks/secrets-stack.ts`: Ollama 관련 파라미터 참조
- `packages/cdk/lib/stacks/compute-stack.ts`: OLLAMA_* 환경변수
- `packages/container/Dockerfile`: Ollama 관련 설정 (현재는 없음)
- 문서: `dev/openclaw-ollama-setup.md` (참고용으로 보관하되 사용 불가 명시)

**확인 명령:**
```bash
# SSM Parameters 확인
aws ssm get-parameters-by-path \
  --path "/serverless-openclaw" \
  --region ap-northeast-2 \
  --query "Parameters[?contains(Name, 'OLLAMA')].Name"
```

### 2. Telegram 메시지 테스트 완료 ✅
- Webhook 설정 완료
- Bot: @geoseong_bot
- Gemini 모델로 응답 수신 확인 ✅

### 5. 추가 개선 사항 (선택)
- TaskState 자동 정리 로직 추가 (컨테이너 실패 시)
- CloudWatch 알람 설정 (컨테이너 실패, API 에러)
- 비용 모니터링 설정

## OpenClaw Config 형식 학습 및 성공 사례

### 최종 성공 Config (OpenRouter)
```json
{
  "gateway": {"port": 18789, "mode": "local"},
  "agents": {
    "defaults": {
      "model": {"primary": "openrouter/arcee-ai/trinity-large-preview:free"},
      "models": {
        "openrouter/arcee-ai/trinity-large-preview:free": {"alias": "Trinity Large Preview Free"}
      }
    }
  },
  "models": {
    "providers": {
      "openrouter": {
        "baseUrl": "https://openrouter.ai/api/v1",
        "apiKey": "OPENROUTER_API_KEY",
        "api": "openai-completions",
        "models": [
          {
            "id": "arcee-ai/trinity-large-preview:free",
            "name": "Trinity Large Preview Free",
            "reasoning": false,
            "input": ["text"],
            "cost": {"input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0},
            "contextWindow": 32000,
            "maxTokens": 4096
          }
        ]
      }
    }
  }
}
```
- **결과**: Web UI 메시지 통신 성공 ✅
- **로그**: `agent model: openrouter/arcee-ai/trinity-large-preview:free`

### 사용자 제공 lmstudio 예시 (참고)
```json
{
  "agents": {
    "defaults": {
      "model": {"primary": "lmstudio/minimax-m2.1-gs32"},
      "models": {"lmstudio/minimax-m2.1-gs32": {"alias": "Minimax"}}
    }
  },
  "models": {
    "providers": {
      "lmstudio": {
        "baseUrl": "http://localhost:1234/v1",
        "apiKey": "LMSTUDIO_KEY",
        "api": "openai-completions",
        "models": [
          {
            "id": "minimax-m2.1-gs32",
            "name": "MiniMax M2.1",
            "reasoning": false,
            "input": ["text"],
            "cost": {"input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0},
            "contextWindow": 200000,
            "maxTokens": 8192
          }
        ]
      }
    }
  }
}
```

### 실패했던 Config 형식들

#### 1. Legacy 형식 (단순 llm)
```json
{
  "gateway": {"port": 18789, "mode": "local"},
  "llm": {
    "provider": "openrouter",
    "model": "arcee-ai/trinity-large-preview:free",
    "baseURL": "https://openrouter.ai/api/v1"
  }
}
```
- **결과**: Gateway가 Anthropic 모델로 덮어씀 ❌

#### 2. agents.default (단수)
```json
{
  "agents": {
    "default": {
      "model": "gemini-3-flash-preview"
    }
  }
}
```
- **결과**: `agents: Unrecognized key: "default"` 에러 ❌

### 핵심 규칙
1. `agents.defaults` (복수) 사용 필수
2. `model.primary` 형식으로 primary 모델 지정
3. `models.providers.<provider>` 구조:
   - `baseUrl`: API endpoint (필수)
   - `apiKey`: 환경변수 이름 또는 실제 키 값
   - `api`: API 타입 (예: "openai-completions")
   - `models`: 모델 정의 배열
4. 각 model 정의:
   - `id`, `name`, `reasoning`, `input`, `cost`, `contextWindow`, `maxTokens`

## OpenClaw Config 관리 방법

`packages/container/openclaw.json` 파일로 관리 중:

```json
{
  "gateway": {
    "port": 18789,
    "mode": "local"
  },
  "models": {
    "default": "gemini-3-flash-preview",
    "providers": {
      "google": {
        "models": [
          {"id": "gemini-3-flash-preview", "name": "Gemini 3 Flash Preview"},
          {"id": "gemini-1.5-flash", "name": "Gemini 1.5 Flash"}
        ]
      },
      "openrouter": {
        "models": [
          {"id": "arcee-ai/trinity-large-preview:free", "name": "Trinity Large Preview Free"}
        ]
      }
    }
  },
  "agents": {
    "default": {
      "type": "pi",
      "model": "gemini-3-flash-preview",
      "maxTokens": 4096,
      "temperature": 0.7
    }
  }
}
```

Dockerfile에서 COPY 방식으로 주입:
```dockerfile
COPY --chown=openclaw:openclaw packages/container/openclaw.json /tmp/openclaw.json
RUN mkdir -p /home/openclaw/.openclaw && \
    cp /tmp/openclaw.json /home/openclaw/.openclaw/openclaw.json && \
    rm /tmp/openclaw.json && \
    chown -R openclaw:openclaw /home/openclaw/.openclaw
```

**장점:**
- Config 가독성 향상 (JSON 포맷팅 유지)
- 버전 관리 용이
- 수정 시 실수 방지 (JSON validation 가능)
- 재사용 가능 (로컬 테스트 시에도 동일 파일 사용)

## 참고 문서
- OpenClaw Config: https://docs.openclaw.ai/concepts/model-providers
- OpenClaw Gateway: https://docs.openclaw.ai/gateway/configuration
- OpenRouter 통합: https://openrouter.ai/docs/guides/guides/openclaw-integration
- 문제 해결: `dev/troubleshooting.md`
- 로컬 테스트: `dev/localtest.md`
- 배포 가이드: `docs/deployment.md`
